{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "8LOf4mvV2nlf",
    "outputId": "d6b51881-042b-4315-ea98-f922d5e01f96"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33000\\1565798135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pandas 0.24.2 has a non-standard dependency specifier pytz>=2011k. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pandas or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "  WARNING: Failed to remove contents in a temporary directory 'c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray 0.20.1 requires pandas>=1.1, but you have pandas 0.24.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.11.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting numpy>=1.20 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl.metadata (807 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (47.3.1.post20200622)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading grpcio-1.62.3-cp37-cp37m-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.34.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\benjamenalford\\.conda\\envs\\pythondata\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "   ---------------------------------------- 266.3/266.3 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.3-cp37-cp37m-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 4.5/4.5 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading h5py-3.8.0-cp37-cp37m-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 2.6/2.6 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 1.7/1.7 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 26.4/26.4 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "   ---------------------------------------- 14.0/14.0 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "   --------------------------------------- 896.6/896.6 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "   ---------------------------------------- 6.0/6.0 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "   --------------------------------------- 439.2/439.2 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading wrapt-1.16.0-cp37-cp37m-win_amd64.whl (37 kB)\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "   --------------------------------------- 200.9/200.9 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "   --------------------------------------- 781.3/781.3 kB 16.4 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "   --------------------------------------- 181.3/181.3 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 84.9/84.9 kB ? eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, h5py, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.5.0 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.34.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.62.3 h5py-3.8.0 keras-2.11.0 libclang-18.1.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SPHEQ</th>\n",
       "      <th>AL</th>\n",
       "      <th>ACD</th>\n",
       "      <th>LT</th>\n",
       "      <th>VCD</th>\n",
       "      <th>SPORTHR</th>\n",
       "      <th>READHR</th>\n",
       "      <th>COMPHR</th>\n",
       "      <th>STUDYHR</th>\n",
       "      <th>TVHR</th>\n",
       "      <th>DIOPTERHR</th>\n",
       "      <th>MOMMY</th>\n",
       "      <th>DADMY</th>\n",
       "      <th>MYOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>21.889999</td>\n",
       "      <td>3.690</td>\n",
       "      <td>3.498</td>\n",
       "      <td>14.70</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.608</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>3.702</td>\n",
       "      <td>3.392</td>\n",
       "      <td>15.29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.179</td>\n",
       "      <td>22.490000</td>\n",
       "      <td>3.462</td>\n",
       "      <td>3.514</td>\n",
       "      <td>15.52</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.525</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>3.862</td>\n",
       "      <td>3.612</td>\n",
       "      <td>14.73</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.697</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>3.676</td>\n",
       "      <td>3.454</td>\n",
       "      <td>16.16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SPHEQ         AL    ACD     LT    VCD  SPORTHR  READHR  COMPHR  \\\n",
       "0    6 -0.052  21.889999  3.690  3.498  14.70       45       8       0   \n",
       "1    6  0.608  22.379999  3.702  3.392  15.29        4       0       1   \n",
       "2    6  1.179  22.490000  3.462  3.514  15.52       14       0       2   \n",
       "3    6  0.525  22.200001  3.862  3.612  14.73       18      11       0   \n",
       "4    5  0.697  23.290001  3.676  3.454  16.16       14       0       0   \n",
       "\n",
       "   STUDYHR  TVHR  DIOPTERHR  MOMMY  DADMY  MYOPIC  \n",
       "0        0    10         34      1      1       1  \n",
       "1        1     7         12      1      1       0  \n",
       "2        0    10         14      0      0       0  \n",
       "3        0     4         37      0      1       1  \n",
       "4        0     4          4      1      0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "myopia_df = pd.read_csv('Resources/myopia.csv')\n",
    "myopia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mnUA9Jz2nlp"
   },
   "outputs": [],
   "source": [
    "# Remove MYOPIC target from features data\n",
    "y = myopia_df.MYOPIC.values\n",
    "X = myopia_df.drop(columns=\"MYOPIC\").values\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reOMnWTW2nlq"
   },
   "outputs": [],
   "source": [
    "# Preprocess numerical data for neural network\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJP8qIlU2nlq",
    "outputId": "96c0759d-3ac4-4cb1-c3b2-bd2f50ac50f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 16:06:53.010503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 2ms/step - loss: 0.7046 - accuracy: 0.5032\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7019\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8229\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8639\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8683\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8683\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8683\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8683\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8683\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8683\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8683\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8683\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8683\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8683\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8683\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8683\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8704\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8704\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8726\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8726\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8747\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.8747\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8790\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.8855\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8877\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8898\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8963\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.9006\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9028\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9006\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9006\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9050\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9093\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9093\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9114\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9158\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9136\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9158\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9201\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9179\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9201\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9136\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9158\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9201\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9222\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.9222\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9222\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9287\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9330\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9309\n",
      "5/5 - 0s - loss: 0.4352 - accuracy: 0.8645 - 127ms/epoch - 25ms/step\n",
      "Loss: 0.4351870119571686, Accuracy: 0.8645161390304565\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=14))\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUleMxww2nlr"
   },
   "outputs": [],
   "source": [
    "nn_model.save(\"my_model.hr5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.load_model(\"my_model.hr5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DetectingDiabetes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
