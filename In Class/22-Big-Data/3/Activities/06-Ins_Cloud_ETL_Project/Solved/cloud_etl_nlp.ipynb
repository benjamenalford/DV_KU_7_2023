{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YV4ajtm-iijA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.2.2'\n",
    "spark_version = 'spark-<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "21VIzGHIioxp"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CloudETLProject\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGQc0BlXit96",
    "outputId": "cb340497-80d9-4f35-b159-f0bb3e653c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------+-----------------+-----------+\n",
      "|                 _c0|            drugName|           condition|              review|rating|             date|usefulCount|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+-----------------+-----------+\n",
      "|              206461|           Valsartan|Left Ventricular ...|\"\"\"It has no side...|   9.0|     May 20, 2012|         27|\n",
      "|               95260|          Guanfacine|                ADHD|\"\"\"My son is half...|  null|             null|       null|\n",
      "|We have tried man...|                 8.0|      April 27, 2010|                 192|  null|             null|       null|\n",
      "|               92703|              Lybrel|       Birth Control|\"\"\"I used to take...|  null|             null|       null|\n",
      "|The positive side...|                 5.0|   December 14, 2009|                  17|  null|             null|       null|\n",
      "|              138000|          Ortho Evra|       Birth Control|\"\"\"This is my fir...|   8.0| November 3, 2015|         10|\n",
      "|               35696|Buprenorphine / n...|   Opiate Dependence|\"\"\"Suboxone has c...|   9.0|November 27, 2016|         37|\n",
      "|              155963|              Cialis|Benign Prostatic ...|\"\"\"2nd day on 5mg...|   2.0|November 28, 2015|         43|\n",
      "|              165907|      Levonorgestrel|Emergency Contrac...|\"\"\"He pulled out,...|   1.0|    March 7, 2017|          5|\n",
      "|              102654|        Aripiprazole|     Bipolar Disorde|\"\"\"Abilify change...|  10.0|   March 14, 2015|         32|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+-----------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "# Load in data into a DataFrame\n",
    "\n",
    "url = \"/content/drive/MyDrive/Colab Notebooks/2U/etl/06-Stu_Cloud_ETL_Project/Solved/drugsComTrain_raw.tsv\" #enter correct address here\n",
    "#spark.sparkContext.addFile(url) No need for sparkcontext if read from google drive\n",
    "\n",
    "df = spark.read.option('header', 'true').csv(SparkFiles.get(url), inferSchema=True, sep='\\t', timestampFormat=\"mm/dd/yy\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHrs8Uk1i0RX"
   },
   "source": [
    "## Transform DataFrame to fit review_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvpPZ1TEiwyu",
    "outputId": "c9fd21bc-96d7-42dd-d614-2b4a83415557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|              review|rating|             date|\n",
      "+--------------------+------+-----------------+\n",
      "|\"\"\"It has no side...|   9.0|     May 20, 2012|\n",
      "|\"\"\"My son is half...|  null|             null|\n",
      "|                 192|  null|             null|\n",
      "|\"\"\"I used to take...|  null|             null|\n",
      "|                  17|  null|             null|\n",
      "|\"\"\"This is my fir...|   8.0| November 3, 2015|\n",
      "|\"\"\"Suboxone has c...|   9.0|November 27, 2016|\n",
      "|\"\"\"2nd day on 5mg...|   2.0|November 28, 2015|\n",
      "|\"\"\"He pulled out,...|   1.0|    March 7, 2017|\n",
      "|\"\"\"Abilify change...|  10.0|   March 14, 2015|\n",
      "|\"\"\" I Ve had  not...|   1.0|   August 9, 2016|\n",
      "|\"\"\"I had been on ...|   8.0| December 8, 2016|\n",
      "|\"\"\"I have been on...|   9.0|  January 1, 2015|\n",
      "|\"\"\"I have taken a...|  null|             null|\n",
      "|                null|  null|             null|\n",
      "|                  54|  null|             null|\n",
      "|\"\"\"I had Crohn&#0...|   4.0|     July 6, 2013|\n",
      "|\"\"\"Have a little ...|   4.0|September 7, 2017|\n",
      "|\"\"\"Started Nexpla...|  null|             null|\n",
      "|                  10|  null|             null|\n",
      "+--------------------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_df = df.select([\"review\",\"rating\", \"date\"])\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWBjwNJqzr5l",
    "outputId": "39220d2d-962a-47af-e3bc-521beccfc29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+--------------------+-------------+\n",
      "|label|              date|              review|review_length|\n",
      "+-----+------------------+--------------------+-------------+\n",
      "|  9.0|      May 20, 2012|\"\"\"It has no side...|           83|\n",
      "|  8.0|  November 3, 2015|\"\"\"This is my fir...|          452|\n",
      "|  9.0| November 27, 2016|\"\"\"Suboxone has c...|          723|\n",
      "|  2.0| November 28, 2015|\"\"\"2nd day on 5mg...|          407|\n",
      "|  1.0|     March 7, 2017|\"\"\"He pulled out,...|          146|\n",
      "| 10.0|    March 14, 2015|\"\"\"Abilify change...|          737|\n",
      "|  1.0|    August 9, 2016|\"\"\" I Ve had  not...|          197|\n",
      "|  8.0|  December 8, 2016|\"\"\"I had been on ...|          741|\n",
      "|  9.0|   January 1, 2015|\"\"\"I have been on...|          734|\n",
      "|  4.0|      July 6, 2013|\"\"\"I had Crohn&#0...|          407|\n",
      "|  4.0| September 7, 2017|\"\"\"Have a little ...|          595|\n",
      "|  9.0|  January 19, 2017|\"\"\"I have been ta...|          737|\n",
      "|  9.0|September 22, 2017|\"\"\"This drug work...|          680|\n",
      "|  9.0|    March 15, 2017|\"\"\"I&#039;ve been...|          715|\n",
      "| 10.0|  November 9, 2014|\"\"\"I&#039;ve been...|          774|\n",
      "| 10.0| September 1, 2015|\"\"\"I have been on...|          484|\n",
      "|  8.0|      July 9, 2010|\"\"\"Spring of 2008...|          528|\n",
      "| 10.0|     April 3, 2016|\"\"\"I have insomni...|          761|\n",
      "|  9.0|   August 11, 2014|\"\"\"Nexplanon does...|          430|\n",
      "| 10.0|September 16, 2017|\"\"\"I live in West...|          762|\n",
      "+-----+------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, length\n",
    "review_df = df.withColumnRenamed(\"rating\", \"label\").select([\"label\", \"date\", \"review\"])\n",
    "review_df = review_df.withColumn('review_length', length(review_df['review'])).dropna()\n",
    "review_df.cache()\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nRtLVc7i8gK"
   },
   "source": [
    "## Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DPFN7XcGiwtP"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "# Create all the features to the data set\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CxsBBQRiiwk-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors (merge idf_token and review_length)\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'review_length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nQ6f6eXfjDfD"
   },
   "outputs": [],
   "source": [
    "# Create and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_ZkNHtAjGUS"
   },
   "source": [
    "## Transform DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fbq2d16jjDcQ"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(review_df)\n",
    "cleaned = cleaner.transform(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "iAIOltOojKal",
    "outputId": "b84e4249-ae5d-4b64-decd-04e85e4cf9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    5|(262145,[9639,991...|\n",
      "|    4|(262145,[512,1588...|\n",
      "|    4|(262145,[3578,963...|\n",
      "|    2|(262145,[9639,157...|\n",
      "|    4|(262145,[3294,736...|\n",
      "|    4|(262145,[14,8443,...|\n",
      "|    4|(262145,[14,604,3...|\n",
      "|    5|(262145,[14,4543,...|\n",
      "|    3|(262145,[3890,392...|\n",
      "|    5|(262145,[991,2437...|\n",
      "|    4|(262145,[14,326,3...|\n",
      "|    3|(262145,[6922,736...|\n",
      "|    3|(262145,[6922,963...|\n",
      "|    5|(262145,[4081,158...|\n",
      "|    5|(262145,[1076,199...|\n",
      "|    5|(262145,[14,329,1...|\n",
      "|    5|(262145,[14,1998,...|\n",
      "|    4|(262145,[14,5281,...|\n",
      "|    4|(262145,[7388,963...|\n",
      "|    4|(262145,[9639,158...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show label of ham spam and resulting features\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S37P7oA2jMF9"
   },
   "source": [
    "## Run NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "2_KHNZkqjN-Z"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes() #labelCol='label', featuresCol='features'\n",
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGP2q-_D2one",
    "outputId": "de5614b7-1933-48d4-d54b-1c750b334330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|         date|              review|review_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|April 1, 2009|\"\"\"It made me ext...|           87|[\"\"\"it, made, me,...|[\"\"\"it, made, ext...|(262144,[19923,30...|(262144,[19923,30...|(262145,[19923,30...|\n",
      "|  1.0|April 1, 2014|\"\"\"I have bronchi...|          430|[\"\"\"i, have, bron...|[\"\"\"i, bronchial,...|(262144,[12098,15...|(262144,[12098,15...|(262145,[12098,15...|\n",
      "|  1.0|April 1, 2015|\"\"\"I came down wi...|          349|[\"\"\"i, came, down...|[\"\"\"i, came, flu,...|(262144,[5381,942...|(262144,[5381,942...|(262145,[5381,942...|\n",
      "|  1.0|April 1, 2015|\"\"\"I came down wi...|          349|[\"\"\"i, came, down...|[\"\"\"i, came, flu,...|(262144,[5381,942...|(262144,[5381,942...|(262145,[5381,942...|\n",
      "|  1.0|April 1, 2015|\"\"\"I have been on...|          375|[\"\"\"i, have, been...|[\"\"\"i, victoza, l...|(262144,[11104,19...|(262144,[11104,19...|(262145,[11104,19...|\n",
      "|  1.0|April 1, 2016|\"\"\"Anaphylaxis re...|           87|[\"\"\"anaphylaxis, ...|[\"\"\"anaphylaxis, ...|(262144,[10235,61...|(262144,[10235,61...|(262145,[10235,61...|\n",
      "|  1.0|April 1, 2016|\"\"\"I began Zarah ...|         1491|[\"\"\"i, began, zar...|[\"\"\"i, began, zar...|(262144,[1603,233...|(262144,[1603,233...|(262145,[1603,233...|\n",
      "|  1.0|April 1, 2016|\"\"\"I had been on ...|          686|[\"\"\"i, had, been,...|[\"\"\"i, different,...|(262144,[1546,232...|(262144,[1546,232...|(262145,[1546,232...|\n",
      "|  1.0|April 1, 2016|\"\"\"I was constipa...|          548|[\"\"\"i, was, const...|[\"\"\"i, constipate...|(262144,[1696,232...|(262144,[1696,232...|(262145,[1696,232...|\n",
      "|  1.0|April 1, 2016|\"\"\"I&#039;ve been...|          604|[\"\"\"i&#039;ve, be...|[\"\"\"i&#039;ve, or...|(262144,[1603,145...|(262144,[1603,145...|(262145,[1603,145...|\n",
      "|  1.0|April 1, 2016|\"\"\"I&#039;ve been...|          604|[\"\"\"i&#039;ve, be...|[\"\"\"i&#039;ve, or...|(262144,[1603,145...|(262144,[1603,145...|(262145,[1603,145...|\n",
      "|  1.0|April 1, 2016|\"\"\"I&#039;ve been...|          185|[\"\"\"i&#039;ve, be...|[\"\"\"i&#039;ve, tw...|(262144,[9056,218...|(262144,[9056,218...|(262145,[9056,218...|\n",
      "|  1.0|April 1, 2016|\"\"\"I&#039;ve been...|          269|[\"\"\"i&#039;ve, be...|[\"\"\"i&#039;ve, pi...|(262144,[1546,187...|(262144,[1546,187...|(262145,[1546,187...|\n",
      "|  1.0|April 1, 2016|\"\"\"Not only did i...|           73|[\"\"\"not, only, di...|[\"\"\"not, help, mi...|(262144,[161,3095...|(262144,[161,3095...|(262145,[161,3095...|\n",
      "|  1.0|April 1, 2016|\"\"\"Picked up moni...|          438|[\"\"\"picked, up, m...|[\"\"\"picked, monis...|(262144,[19036,21...|(262144,[19036,21...|(262145,[19036,21...|\n",
      "|  1.0|April 1, 2017|\"\"\"I started sert...|          129|[\"\"\"i, started, s...|[\"\"\"i, started, s...|(262144,[24698,32...|(262144,[24698,32...|(262145,[24698,32...|\n",
      "|  1.0|April 1, 2017|\"\"\"I was prescrib...|          649|[\"\"\"i, was, presc...|[\"\"\"i, prescribed...|(262144,[1797,942...|(262144,[1797,942...|(262145,[1797,942...|\n",
      "|  1.0|April 1, 2017|\"\"\"I&#039;m so ma...|          305|[\"\"\"i&#039;m, so,...|[\"\"\"i&#039;m, mad...|(262144,[19036,27...|(262144,[19036,27...|(262145,[19036,27...|\n",
      "|  1.0|April 1, 2017|\"\"\"Poor results, ...|          135|[\"\"\"poor, results...|[\"\"\"poor, results...|(262144,[19036,95...|(262144,[19036,95...|(262145,[19036,95...|\n",
      "|  1.0|April 1, 2017|\"\"\"This by far ha...|          466|[\"\"\"this, by, far...|[\"\"\"this, far, on...|(262144,[365,3283...|(262144,[365,3283...|(262145,[365,3283...|\n",
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSO42Oc9jPRV",
    "outputId": "a6243be9-263b-4645-e9bc-155637ab2d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|         date|              review|review_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  1.0|April 1, 2008|\"\"\"this medicine ...|          118|[\"\"\"this, medicin...|[\"\"\"this, medicin...|(262144,[71929,86...|(262144,[71929,86...|(262145,[71929,86...|[-656.29562241667...|[0.99999999999999...|       0.0|\n",
      "|  1.0|April 1, 2009|\"\"\"It made me ext...|           87|[\"\"\"it, made, me,...|[\"\"\"it, made, ext...|(262144,[19923,30...|(262144,[19923,30...|(262145,[19923,30...|[-371.37383046607...|[0.90457256368311...|       0.0|\n",
      "|  1.0|April 1, 2016|\"\"\"DO NOT SWITCH!...|          746|[\"\"\"do, not, swit...|[\"\"\"do, switch!, ...|(262144,[2306,232...|(262144,[2306,232...|(262145,[2306,232...|[-4356.6920619523...|[1.0,1.9889144026...|       0.0|\n",
      "|  1.0|April 1, 2016|\"\"\"Headache.pain ...|           70|[\"\"\"headache.pain...|[\"\"\"headache.pain...|(262144,[10890,44...|(262144,[10890,44...|(262145,[10890,44...|[-706.16227431473...|[1.0,3.0572785432...|       0.0|\n",
      "|  1.0|April 1, 2016|\"\"\"I had been on ...|          686|[\"\"\"i, had, been,...|[\"\"\"i, different,...|(262144,[1546,232...|(262144,[1546,232...|(262145,[1546,232...|[-3172.5412105600...|[1.0,8.4730170234...|       0.0|\n",
      "+-----+-------------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tik9-ZskjPvO"
   },
   "source": [
    "## Predict accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuFyog8-jQCQ",
    "outputId": "38eb8c12-8881-43f3-c711-d9fbe1ee3c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.067418\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cloud_etl_nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
